#!/usr/bin/env python3
"""
CoT ì¦ê°• ë°ì´í„° í’ˆì§ˆ ê²€ì¦
- <think> íƒœê·¸ í™•ì¸
- ì¤‘êµ­ì–´ í¬í•¨ ì—¬ë¶€ í™•ì¸
- ë‹µë³€ ê¸¸ì´ ê²€ì¦
- ìƒ˜í”Œ ì¶œë ¥
"""

import json
import random
import argparse
import re
from pathlib import Path
from typing import Optional


def has_chinese(text: str) -> bool:
    """ì¤‘êµ­ì–´ í¬í•¨ ì—¬ë¶€ í™•ì¸"""
    return bool(re.search(r'[\u4e00-\u9fff]+', text))


def has_think_tags(text: str) -> bool:
    """<think> íƒœê·¸ í¬í•¨ ì—¬ë¶€ í™•ì¸"""
    return '<think>' in text and '</think>' in text


def extract_think_content(text: str) -> Optional[str]:
    """<think> íƒœê·¸ ë‚´ìš© ì¶”ì¶œ"""
    match = re.search(r'<think>(.*?)</think>', text, re.DOTALL)
    if match:
        return match.group(1).strip()
    return None


def extract_answer_content(text: str) -> str:
    """</think> ì´í›„ ìµœì¢… ë‹µë³€ ì¶”ì¶œ"""
    parts = text.split('</think>')
    if len(parts) > 1:
        return parts[1].strip()
    return text


def validate_augmented_data(
    jsonl_path: str,
    num_samples: int = 20,
    show_full: bool = False,
    output_bad_samples: bool = False
):
    """ìƒì„±ëœ ë°ì´í„° í’ˆì§ˆ í™•ì¸"""
    
    jsonl_path = Path(jsonl_path)
    
    if not jsonl_path.exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {jsonl_path}")
        return
    
    print(f"\nğŸ” í’ˆì§ˆ ê²€ì¦: {jsonl_path.name}")
    print(f"{'='*80}\n")
    
    # ë°ì´í„° ë¡œë“œ
    with open(jsonl_path, 'r', encoding='utf-8') as f:
        data = [json.loads(line) for line in f if line.strip()]
    
    print(f"ğŸ“Š ì´ ìƒ˜í”Œ ìˆ˜: {len(data):,}ê°œ")
    
    # ìƒ˜í”Œë§
    if num_samples > len(data):
        num_samples = len(data)
        print(f"   (ì „ì²´ ìƒ˜í”Œ ê²€ì¦)")
    else:
        print(f"   ({num_samples}ê°œ ìƒ˜í”Œ ê²€ì¦)")
    
    samples = random.sample(data, num_samples)
    
    # í’ˆì§ˆ ì´ìŠˆ ì¶”ì 
    issues = {
        'no_think_tag': 0,
        'has_chinese': 0,
        'too_short': 0,
        'no_steps': 0,
        'good': 0
    }
    
    bad_samples = []
    
    # ê° ìƒ˜í”Œ ê²€ì¦
    for i, sample in enumerate(samples, 1):
        # assistant ë©”ì‹œì§€ ì°¾ê¸°
        assistant_msg = None
        for msg in sample.get('messages', []):
            if msg['role'] == 'assistant':
                assistant_msg = msg
                break
        
        if not assistant_msg:
            print(f"[ìƒ˜í”Œ {i}] âŒ assistant ë©”ì‹œì§€ ì—†ìŒ")
            issues['no_think_tag'] += 1
            bad_samples.append(sample)
            continue
        
        content = assistant_msg['content']
        sample_type = sample.get('type', 'unknown')
        
        print(f"\n{'â”€'*80}")
        print(f"[ìƒ˜í”Œ {i}] - íƒ€ì…: {sample_type}")
        print(f"{'â”€'*80}")
        
        # ê²€ì¦
        has_think = has_think_tags(content)
        has_chinese_content = has_chinese(content)
        is_short = len(content) < 100
        
        # <think> íƒœê·¸ ë‚´ë¶€ ê²€ì‚¬
        has_steps = False
        if has_think:
            think_content = extract_think_content(content)
            if think_content:
                # "1ë‹¨ê³„:", "2ë‹¨ê³„:" ë“±ì˜ íŒ¨í„´ í™•ì¸
                has_steps = bool(re.search(r'\d+ë‹¨ê³„:', think_content))
        
        # ë‚´ìš© ì¶œë ¥
        if show_full or not has_think or has_chinese_content:
            print(content)
        else:
            # ìš”ì•½ ì¶œë ¥
            think_content = extract_think_content(content)
            answer_content = extract_answer_content(content)
            
            print("\n[ì¶”ë¡  ê³¼ì •]")
            if think_content:
                think_lines = think_content.split('\n')[:5]  # ì²˜ìŒ 5ì¤„ë§Œ
                for line in think_lines:
                    print(f"  {line}")
                if len(think_content.split('\n')) > 5:
                    print("  ...")
            
            print("\n[ìµœì¢… ë‹µë³€]")
            answer_preview = answer_content[:200] + "..." if len(answer_content) > 200 else answer_content
            print(f"  {answer_preview}")
        
        # í’ˆì§ˆ í‰ê°€
        print(f"\n[í’ˆì§ˆ í‰ê°€]")
        
        if not has_think:
            issues['no_think_tag'] += 1
            print("  âŒ <think> íƒœê·¸ ì—†ìŒ")
            bad_samples.append(sample)
        elif has_chinese_content:
            issues['has_chinese'] += 1
            print("  âš ï¸  ì¤‘êµ­ì–´ í¬í•¨")
            bad_samples.append(sample)
        elif is_short:
            issues['too_short'] += 1
            print("  âš ï¸  ë‹µë³€ì´ ë„ˆë¬´ ì§§ìŒ (100ì ë¯¸ë§Œ)")
        elif not has_steps:
            issues['no_steps'] += 1
            print("  âš ï¸  ë‹¨ê³„ë³„ êµ¬ë¶„ ì—†ìŒ (1ë‹¨ê³„:, 2ë‹¨ê³„: ë“±)")
        else:
            issues['good'] += 1
            print("  âœ… í’ˆì§ˆ ì–‘í˜¸")
    
    # í†µê³„ ì¶œë ¥
    print(f"\n{'='*80}")
    print(f"ğŸ“Š í’ˆì§ˆ í†µê³„ ({num_samples}ê°œ ìƒ˜í”Œ)")
    print(f"{'='*80}")
    
    for issue, count in issues.items():
        percentage = (count / num_samples) * 100
        emoji = "âœ…" if issue == 'good' else "âš ï¸" if count > 0 else "âœ…"
        issue_name = {
            'no_think_tag': '<think> íƒœê·¸ ì—†ìŒ',
            'has_chinese': 'ì¤‘êµ­ì–´ í¬í•¨',
            'too_short': 'ë‹µë³€ ë„ˆë¬´ ì§§ìŒ',
            'no_steps': 'ë‹¨ê³„ë³„ êµ¬ë¶„ ì—†ìŒ',
            'good': 'í’ˆì§ˆ ì–‘í˜¸'
        }[issue]
        
        print(f"{emoji} {issue_name}: {count}/{num_samples} ({percentage:.1f}%)")
    
    # ì „ì²´ í’ˆì§ˆ ì ìˆ˜
    quality_score = (issues['good'] / num_samples) * 100
    print(f"\nğŸ¯ ì „ì²´ í’ˆì§ˆ ì ìˆ˜: {quality_score:.1f}%")
    
    if quality_score >= 80:
        print("   âœ… ìš°ìˆ˜ (80% ì´ìƒ)")
    elif quality_score >= 60:
        print("   âš ï¸  ì–‘í˜¸ (60-80%)")
    else:
        print("   âŒ ê°œì„  í•„ìš” (60% ë¯¸ë§Œ)")
    
    # ë¬¸ì œ ìƒ˜í”Œ ì €ì¥
    if output_bad_samples and bad_samples:
        bad_samples_file = jsonl_path.parent / f"{jsonl_path.stem}_bad_samples.jsonl"
        with open(bad_samples_file, 'w', encoding='utf-8') as f:
            for sample in bad_samples:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')
        
        print(f"\nğŸ“ ë¬¸ì œ ìƒ˜í”Œ ì €ì¥: {bad_samples_file}")
        print(f"   ({len(bad_samples)}ê°œ)")
    
    return {
        'total_samples': len(data),
        'validated_samples': num_samples,
        'issues': issues,
        'quality_score': quality_score
    }


def validate_directory(
    dir_path: str,
    num_samples: int = 20,
    output_report: bool = True
):
    """ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  JSONL íŒŒì¼ ê²€ì¦"""
    
    dir_path = Path(dir_path)
    
    if not dir_path.exists():
        print(f"âŒ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {dir_path}")
        return
    
    jsonl_files = list(dir_path.glob('*.jsonl'))
    
    if not jsonl_files:
        print(f"âŒ JSONL íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {dir_path}")
        return
    
    print(f"\n{'='*80}")
    print(f"ğŸ“ ë””ë ‰í† ë¦¬ ê²€ì¦: {dir_path}")
    print(f"{'='*80}")
    print(f"ë°œê²¬ëœ íŒŒì¼: {len(jsonl_files)}ê°œ\n")
    
    all_results = {}
    
    for jsonl_file in sorted(jsonl_files):
        result = validate_augmented_data(
            jsonl_path=str(jsonl_file),
            num_samples=num_samples,
            show_full=False,
            output_bad_samples=False
        )
        
        all_results[jsonl_file.name] = result
        print("\n")
    
    # ì „ì²´ ë¦¬í¬íŠ¸
    if output_report:
        print(f"\n{'='*80}")
        print(f"ğŸ“‹ ì „ì²´ ìš”ì•½ ë¦¬í¬íŠ¸")
        print(f"{'='*80}\n")
        
        total_samples = 0
        total_good = 0
        total_validated = 0
        
        for filename, result in all_results.items():
            total_samples += result['total_samples']
            total_validated += result['validated_samples']
            total_good += result['issues']['good']
            
            print(f"ğŸ“„ {filename}")
            print(f"   ì´ ìƒ˜í”Œ: {result['total_samples']:,}ê°œ")
            print(f"   í’ˆì§ˆ ì ìˆ˜: {result['quality_score']:.1f}%")
            print()
        
        overall_quality = (total_good / total_validated) * 100 if total_validated > 0 else 0
        
        print(f"ğŸ¯ ì „ì²´ í†µê³„:")
        print(f"   ì´ íŒŒì¼: {len(all_results)}ê°œ")
        print(f"   ì´ ìƒ˜í”Œ: {total_samples:,}ê°œ")
        print(f"   ê²€ì¦ ìƒ˜í”Œ: {total_validated:,}ê°œ")
        print(f"   ì „ì²´ í’ˆì§ˆ ì ìˆ˜: {overall_quality:.1f}%")
        
        # ë¦¬í¬íŠ¸ ì €ì¥
        report_file = dir_path / 'quality_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump({
                'summary': {
                    'total_files': len(all_results),
                    'total_samples': total_samples,
                    'validated_samples': total_validated,
                    'overall_quality': overall_quality
                },
                'files': all_results
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“Š ë¦¬í¬íŠ¸ ì €ì¥: {report_file}")


def main():
    parser = argparse.ArgumentParser(description="CoT ë°ì´í„° í’ˆì§ˆ ê²€ì¦")
    parser.add_argument(
        'path',
        type=str,
        help='ê²€ì¦í•  JSONL íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬'
    )
    parser.add_argument(
        '--num-samples',
        type=int,
        default=20,
        help='ê²€ì¦í•  ìƒ˜í”Œ ìˆ˜'
    )
    parser.add_argument(
        '--show-full',
        action='store_true',
        help='ì „ì²´ ë‚´ìš© ì¶œë ¥'
    )
    parser.add_argument(
        '--output-bad',
        action='store_true',
        help='ë¬¸ì œ ìƒ˜í”Œ ë³„ë„ ì €ì¥'
    )
    parser.add_argument(
        '--directory',
        action='store_true',
        help='ë””ë ‰í† ë¦¬ ëª¨ë“œ (ëª¨ë“  JSONL ê²€ì¦)'
    )
    
    args = parser.parse_args()
    
    if args.directory or Path(args.path).is_dir():
        validate_directory(
            dir_path=args.path,
            num_samples=args.num_samples,
            output_report=True
        )
    else:
        validate_augmented_data(
            jsonl_path=args.path,
            num_samples=args.num_samples,
            show_full=args.show_full,
            output_bad_samples=args.output_bad
        )


if __name__ == "__main__":
    main()

